{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import lime\n",
    "import shap\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "code_dir = os.path.split(os.getcwd())[0]\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "base_dir = \"/\".join(code_dir.split('/')[:-1])\n",
    "sys.path.append(f\"{base_dir}/code/turing/examples-raw/gluesst_finetune/\")\n",
    "sys.path.append(f\"{base_dir}/code/turing/src/\")\n",
    "\n",
    "from argparse import Namespace\n",
    "from methods.bag_of_ngrams.processing import cleanReports, cleanSplit, stripChars\n",
    "from pyfunctions.general import extractListFromDic, readJson\n",
    "from pyfunctions.pathology import extract_synoptic, fixProstateLabels, fixLabel, exclude_labels\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from turing.pathology.run_classifier import MODEL_CLASSES, processors, train_path as train\n",
    "from methods.torch.processing import make_weights_for_balanced_classes\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from turing.pathology.path_utils import evaluate, extract_features, load_tnlr_base, load_tnlr_tokenizer, path_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "args = {\n",
    "    'model_name_or_path': '',\n",
    "    'task_name': 'sst-2',\n",
    "    'config_name': '',\n",
    "    'tokenizer_name': '',\n",
    "    'do_train': True,\n",
    "    'do_eval': True,\n",
    "    'evaluate_during_training': True,\n",
    "    'max_seq_length': 512,\n",
    "    'do_lower_case': True,\n",
    "    'per_gpu_train_batch_size': 8,\n",
    "    'per_gpu_eval_batch_size': 8,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 7.6e-6,\n",
    "    'weight_decay': 0.01,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'max_grad_norm': 1,\n",
    "    'max_steps': -1,\n",
    "    'warmup_ratio': 0.2,\n",
    "    'logging_steps': 50,\n",
    "    'eval_all_checkpoints': True,\n",
    "    'no_cuda': False,\n",
    "    'overwrite_output_dir': True,\n",
    "    'seed': 42,\n",
    "    'overwrite_cache': True,\n",
    "    'metric_for_choose_best_checkpoint': None,\n",
    "    'fp16': False,\n",
    "    'fp16_opt_level': 'O1',\n",
    "    'local_rank': -1,\n",
    "    'num_train_epochs': 25,\n",
    "    'n_gpu': 1,\n",
    "    'device': 'cuda',\n",
    "    'model_type': 'clinical_biobert'\n",
    "}\n",
    "\n",
    "# Read in data\n",
    "path = f\"{base_dir}/path_nlp_turing/data/prostate.json\"\n",
    "data = readJson(path)\n",
    "\n",
    "# Clean reports\n",
    "data = cleanSplit(data, stripChars)\n",
    "data['dev_test'] = cleanReports(data['dev_test'], stripChars)\n",
    "\n",
    "data = fixLabel(data)\n",
    "\n",
    "kwargs = Namespace(**args)\n",
    "\n",
    "# Tokenizer\n",
    "if args['model_type'] == 'bert':\n",
    "    bert_path = 'bert-base-uncased'\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "elif args['model_type'] == 'pubmed_bert':\n",
    "    bert_path = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", local_files_only=False)\n",
    "elif args['model_type'] == 'biobert':\n",
    "    bert_path = \"dmis-lab/biobert-v1.1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\", local_files_only=False)\n",
    "elif args['model_type'] == 'clinical_biobert':\n",
    "    bert_path = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", local_files_only=False)\n",
    "elif args['model_type'] == 'tnlr':\n",
    "    checkpoint_file = f'{base_dir}/path_nlp_turing/turing/src/tnlr/checkpoints/tnlrv3-base.pt'\n",
    "    config_file = f'{base_dir}/path_nlp_turing/turing/src/tnlr/config/tnlr-base-uncased-config.json'\n",
    "    vocab_file = f'{base_dir}/path_nlp_turing/turing/src/tnlr/tokenizer/tnlr-uncased-vocab.txt'\n",
    "    tokenizer = load_tnlr_tokenizer(vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Evaluate on best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2066 517 324\n",
      "{'0': 0, '1': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [01:07<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeminalVesicleNone_0\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          33    9\n",
      "1           1  281\n",
      "\n",
      "\n",
      "2066 517 324\n",
      "{'0': 0, '1': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [01:07<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeminalVesicleNone_1\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          30   10\n",
      "1           1  283\n",
      "\n",
      "\n",
      "2066 517 324\n",
      "{'0': 0, '1': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:54<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeminalVesicleNone_2\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          28    6\n",
      "1           3  287\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is working evaluation code -- Mar 17 2023\n",
    "\n",
    "fields = ['SeminalVesicleNone']#'PrimaryGleason', 'SecondaryGleason', 'MarginStatusNone', 'SeminalVesicleNone']\n",
    "results = {field: {'macro': [], 'micro': []} for field in fields}\n",
    "\n",
    "for i in range(3):\n",
    "    args['run'] = i\n",
    "    \n",
    "    for field in fields:\n",
    "        train_documents = [extract_synoptic(patient['document'].lower(), tokenizer) for patient in data['train']]\n",
    "        train_labels = [patient['labels'][field] for patient in data['train']]\n",
    "        \n",
    "        val_documents = [extract_synoptic(patient['document'].lower(), tokenizer) for patient in data['val']]\n",
    "        val_labels = [patient['labels'][field] for patient in data['val']]\n",
    "        \n",
    "        test_documents = [extract_synoptic(patient['document'].lower(), tokenizer) for patient in data['test']]\n",
    "        test_labels = [patient['labels'][field] for patient in data['test']]\n",
    "        \n",
    "        if field in ['PrimaryGleason', 'SecondaryGleason']:\n",
    "            train_documents, train_labels = exclude_labels(train_documents, train_labels)\n",
    "            val_documents, val_labels = exclude_labels(val_documents, val_labels)\n",
    "            test_documents, test_labels = exclude_labels(test_documents, test_labels)\n",
    "\n",
    "        print(len(train_documents), len(val_documents), len(test_documents))\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train_labels)\n",
    "\n",
    "        # Map raw label to processed label\n",
    "        le_dict = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        le_dict = {str(key):le_dict[key] for key in le_dict}\n",
    "\n",
    "        for label in val_labels + test_labels:\n",
    "            if str(label) not in le_dict:\n",
    "                le_dict[str(label)] = len(le_dict)\n",
    "                \n",
    "        train_labels = [le_dict[str(label)] for label in train_labels]\n",
    "        val_labels = [le_dict[str(label)] for label in val_labels]\n",
    "        test_labels = [le_dict[str(label)] for label in test_labels]\n",
    "\n",
    "        # Map processed label back to raw label\n",
    "        inv_le_dict = {v: k for k, v in le_dict.items()}\n",
    "        print(le_dict)\n",
    "        \n",
    "        documents_full = train_documents + val_documents + test_documents\n",
    "        labels_full = train_labels + val_labels + test_labels\n",
    "\n",
    "        p_test = len(test_labels)/len(labels_full)\n",
    "        p_val = len(val_labels)/(len(train_labels) + len(val_labels))\n",
    "\n",
    "        train_documents, test_documents, train_labels, test_labels = train_test_split(documents_full, \n",
    "                                                                                      labels_full, \n",
    "                                                                                      test_size= p_test,\n",
    "                                                                                      random_state=args['run'])\n",
    "\n",
    "        train_documents, val_documents, train_labels, val_labels = train_test_split(train_documents, \n",
    "                                                                                      train_labels, \n",
    "                                                                                      test_size= p_val,\n",
    "                                                                                      random_state=args['run'])\n",
    "        \n",
    "\n",
    "        model_path = f\"{base_dir}/path_nlp_turing/output/fine_tuning/{args['model_type']}_{args['run']}/{field}\"\n",
    "        checkpoint_file = f\"{model_path}/save_output\"\n",
    "        config_file = f\"{model_path}/save_output/config.json\"\n",
    "        \n",
    "        if args['model_type'] != 'tnlr':\n",
    "            model = BertForSequenceClassification.from_pretrained(checkpoint_file, num_labels=len(le_dict))\n",
    "        else:\n",
    "            model = load_tnlr_base(checkpoint_file, config_file, model_type='tnlrv3_classification', num_labels=len(le_dict))\n",
    "\n",
    "        with torch.cuda.device(1):\n",
    "            model = model.cuda()\n",
    "\n",
    "            test_dataset = path_dataset(test_documents, test_labels, model, tokenizer)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=kwargs.per_gpu_train_batch_size)\n",
    "            output, labels, preds = evaluate(test_dataloader, kwargs, model, tokenizer, prefix=\"\")\n",
    "            \n",
    "        results[field]['micro'].append(output['micro'])\n",
    "        results[field]['macro'].append(output['macro'])\n",
    "        \n",
    "        preds = [inv_le_dict[pred] for pred in preds]\n",
    "        labels = [inv_le_dict[label] for label in labels]\n",
    "                                    \n",
    "        y_actu = pd.Series(labels, name='Actual')\n",
    "        y_pred = pd.Series(preds, name='Predicted')\n",
    "        df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "                                    \n",
    "        print(f\"{field}_{args['run']}\")\n",
    "        print(df_confusion)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        del model\n",
    "        del test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average micro 0.969 0.00244948974278318\n",
      "Average macro 0.9203333333333333 0.005249338582674546\n"
     ]
    }
   ],
   "source": [
    "averages_mi, averages_ma = [], []\n",
    "\n",
    "for run in range(3):\n",
    "    average_mi, average_ma = [], []\n",
    "    for field in results:\n",
    "        average_mi.append(results[field]['micro'][run])\n",
    "        average_ma.append(results[field]['macro'][run])\n",
    "    averages_mi.append(np.mean(average_mi))\n",
    "    averages_ma.append(np.mean(average_ma))\n",
    "        \n",
    "print(f\"Average micro {np.mean(averages_mi)} {np.std(averages_mi)}\")\n",
    "print(f\"Average macro {np.mean(averages_ma)} {np.std(averages_ma)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
